---
title: "Session 4: Variational autoencoders"
author: "Methods seminar: Deep Learning"
date: "01/04/2020"
output:
  html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
solution = TRUE
```

***

Based on [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r) [exercises](https://github.com/jjallaire/deep-learning-with-r-notebooks/edit/master/notebooks/8.4-generating-images-with-vaes.Rmd)


***

Required packages for the exercise: 

```{r}
suppressPackageStartupMessages({
  library(keras)
  library(R6)
  library(ggplot2)
})

```


## Default Variational autoencoder

The following code shows in details how VAE is implemented. You don't need to read/ understand all chunks as the exercises in the next session will only focus on some parts. 

Let's quickly go over a Keras implementation of a VAE. Schematically, it looks like this:

```{r, eval=FALSE}
# Encode the input into a mean and variance parameter
c(z_mean, z_log_variance) %<% encoder(input_img)

# Draws a latent point using a small random epsilon
z <- z_mean + exp(z_log_variance) * epsilon 

# Decodes z back to an image
reconstructed_img <- decoder(z) 

# Creates a model
model <- keras_model(input_img, reconstructed_img)

# Then train the model using 2 losses:
# a reconstruction loss and a regularization loss
```

### Encoder 

Here is the encoder network we will use: a very simple convnet which maps the input image `x` to two vectors, `z_mean` and `z_log_variance`.

```{r}


img_shape <- c(28, 28, 1)
batch_size <- 16
latent_dim <- 2L  # Dimensionality of the latent space: a plane

input_img <- layer_input(shape = img_shape)

x <- input_img %>% 
  layer_conv_2d(filters = 32, kernel_size = 3, padding = "same", 
                activation = "relu") %>% 
  layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", 
                activation = "relu", strides = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", 
                activation = "relu") %>%
  layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", 
                activation = "relu") 

shape_before_flattening <- k_int_shape(x)

x <- x %>% 
  layer_flatten() %>% 
  layer_dense(units = 32, activation = "relu")

z_mean <- x %>% 
  layer_dense(units = latent_dim)

z_log_var <- x %>% 
  layer_dense(units = latent_dim)

encoder <- keras_model(input_img, z_mean)

```

### Latent space

Next is the code for using `z_mean` and `z_log_var`, the parameters of the statistical distribution assumed to have produced `input_img`, to generate a latent space point `z`. Here, you wrap some arbitrary code (built on top of Keras backend primitives) into a `layer_lambda()`, which wraps an R function into a layer. 

```{r}
sampling <- function(args) {
  c(z_mean, z_log_var) %<-% args
  epsilon <- k_random_normal(shape = list(k_shape(z_mean)[1], latent_dim),
                             mean = 0, stddev = 1)
  z_mean + k_exp(z_log_var) * epsilon
}

z <- list(z_mean, z_log_var) %>% 
  layer_lambda(sampling)
```

### Decoder 

This is the decoder implementation: we reshape the vector `z` to the dimensions of an image, then we use a few convolution layers to obtain a final image output that has the same dimensions as the original `input_img`.

```{r}

# This is the input where we will feed `z`.
decoder_input <- layer_input(k_int_shape(z)[-1])

x <- decoder_input %>% 
  # Upsample to the correct number of units
  layer_dense(units = prod(as.integer(shape_before_flattening[-1])),
              activation = "relu") %>% 
  # Reshapes into an image of the same shape as before the last flatten layer
  layer_reshape(target_shape = shape_before_flattening[-1]) %>% 
  # Applies and then reverses the operation to the initial stack of 
  # convolution layers
  layer_conv_2d_transpose(filters = 32, kernel_size = 3, padding = "same",
                          activation = "relu", strides = c(2, 2)) %>%  
  layer_conv_2d(filters = 1, kernel_size = 3, padding = "same",
                activation = "sigmoid")  
  # We end up with a feature map of the same size as the original input.

# This is our decoder model.
decoder <- keras_model(decoder_input, x)

# We then apply it to `z` to recover the decoded `z`.
z_decoded <- decoder(z) 

```

The dual loss of a VAE doesn't fit the traditional expectation of a sample-wise function of the form `loss(input, target)`. Thus, we set up the loss by writing a custom layer with internally leverages the built-in `add_loss` layer method to create an arbitrary loss.

```{r}

CustomVariationalLayer <- R6Class("CustomVariationalLayer",
                                  
  inherit = KerasLayer,
  
  public = list(
    
    vae_loss = function(x, z_decoded) { 
      x <- k_flatten(x)
      z_decoded <- k_flatten(z_decoded)
      xent_loss <- metric_binary_crossentropy(x, z_decoded)
      kl_loss <- -5e-4 * k_mean(
        1 + z_log_var - k_square(z_mean) - k_exp(z_log_var), 
        axis = -1L
      )
      k_mean(xent_loss + kl_loss)
    },
    
    call = function(inputs, mask = NULL) {
      x <- inputs[[1]]
      z_decoded <- inputs[[2]]
      loss <- self$vae_loss(x, z_decoded)
      self$add_loss(loss, inputs = inputs)
      x
    }
  )
)

layer_variational <- function(object) { 
  create_layer(CustomVariationalLayer, object, list())
} 

# Call the custom layer on the input and the decoded output to obtain
# the final model output
y <- list(input_img, z_decoded) %>% 
  layer_variational() 

```

Finally, we instantiate and train the model. Since the loss has been taken care of in our custom layer, we don't specify an external loss at compile time (`loss = NULL`), which in turns means that we won't pass target data during training (as you can see we only pass `x_train` to the model in `fit`).

```{r}
vae <- keras_model(input_img, y)

vae %>% compile(
  optimizer = "rmsprop",
  loss = NULL, 
  experimental_run_tf_function = FALSE 
)

# Trains the VAE on MNIST digits
mnist <- dataset_mnist() 
c(c(x_train, y_train), c(x_test, y_test)) %<-% mnist

x_train <- x_train / 255
x_train <- array_reshape(x_train, dim =c(dim(x_train), 1))

x_test <- x_test / 255
x_test <- array_reshape(x_test, dim =c(dim(x_test), 1))

```

### Training 

For time purpose, we already trained the model so that you can simply load it. 

```{r, echo=TRUE, results='hide', eval=FALSE}

    
vae %>% fit(
  x = x_train, y = NULL,
  epochs = 10,
  batch_size = batch_size,
  validation_data = list(x_test, NULL)
)

vae %>% save_model_weights_tf("def_vae/default_vae")
```


```{r}

load_model_weights_tf(vae, "def_vae/default_vae")

```

### Image generation 

Once such a model is trained -- e.g. on MNIST, in our case -- we can use the `decoder` network to turn arbitrary latent space vectors into images:

```{r}

generate_num <- function(n = 15, digit_size = 28) {
  # n  = Number of rows / columns of digits
  # digit_size =  Height / width of digits in pixels
  
  # Transforms linearly spaced coordinates on the unit square through the inverse
  # CDF (ppf) of the Gaussian to produce values of the latent variables z,
  # because the prior of the latent space is Gaussian
  grid_x <- qnorm(seq(0.05, 0.95, length.out = n))
  grid_y <- qnorm(seq(0.05, 0.95, length.out = n))
  
  op <- par(mfrow = c(n, n), mar = c(0,0,0,0), bg = "black")
  for (i in 1:length(grid_x)) {
    yi <- grid_x[[i]]
    for (j in 1:length(grid_y)) {
      xi <- grid_y[[j]]
      z_sample <- matrix(c(xi, yi), nrow = 1, ncol = 2)
      z_sample <- t(replicate(batch_size, z_sample, simplify = "matrix"))
      x_decoded <- decoder %>% predict(z_sample, batch_size = batch_size)
      digit <- array_reshape(x_decoded[1,,,], dim = c(digit_size, digit_size))
      plot(as.raster(digit))
    }
  }
  par(op)
}

generate_num()
```

The grid of sampled digits shows a completely continuous distribution of the different digit classes, with one digit morphing into another as you follow a path through latent space. Specific directions in this space have a meaning, e.g. there is a direction for "four-ness", "one-ness", etc.

## Exercise 1

Visualize the latent space and identify the different classes on a latent 2D place. 

Tip: use the `encoder` model and the `predict` function. 

```{r eval = solution, include = solution}

# Solution
x_test_encoded <- encoder %>% predict(x_test, batch_size = batch_size)
library(ggplot2)
lat_space <- data.frame(ls1 = x_test_encoded[,1], 
                        ls2 = x_test_encoded[,2], 
                        num = as.factor(y_test))
ggplot(lat_space, aes(x=ls1, y=ls2, color = num)) + geom_point()


```


## Exercice 2

Produce a new pannel of numbers, this time using a non-normal distribution. 

What changes with the grid of samples showed in the example ? 


```{r, eval = solution, include = solution}

# Solution
# We can reuse the `generate_num` but using for instance a uniform distribution. 
n = 15
digit_size = 28

grid_x <- runif(n)
grid_y <- runif(n)

op <- par(mfrow = c(n, n), mar = c(0,0,0,0), bg = "black")
for (i in 1:length(grid_x)) {
  yi <- grid_x[[i]]
  for (j in 1:length(grid_y)) {
    xi <- grid_y[[j]]
    z_sample <- matrix(c(xi, yi), nrow = 1, ncol = 2)
    z_sample <- t(replicate(batch_size, z_sample, simplify = "matrix"))
    x_decoded <- decoder %>% predict(z_sample, batch_size = batch_size)
    digit <- array_reshape(x_decoded[1,,,], dim = c(digit_size, digit_size))
    plot(as.raster(digit))
  }
}
par(op)

```

 

## Exercise 3

In this section we will see the importance of the KL loss. 

Recompile the VAE that we created but by removing the KL loss. 

Once you are done, you can load the corresponding VAE's weights that we already trained and generate a new pannel of numbers from it. What changes with the grid of samples showed in the example ? 

```{r eval = solution, include = solution}
library(R6)

CustomVariationalLayer <- R6Class("CustomVariationalLayer",
                                  
  inherit = KerasLayer,
  
  public = list(
    
    vae_loss = function(x, z_decoded) {
      x <- k_flatten(x)
      z_decoded <- k_flatten(z_decoded)
      xent_loss <- metric_binary_crossentropy(x, z_decoded)
      # kl_loss <- -5e-4 * k_mean(
      #   1 + z_log_var - k_square(z_mean) - k_exp(z_log_var), 
      #   axis = -1L
      # )
      k_mean(xent_loss) ## <--- no more KL loss in the loss function, only reconstruction loss
    },
    
    call = function(inputs, mask = NULL) {
      x <- inputs[[1]]
      z_decoded <- inputs[[2]]
      loss <- self$vae_loss(x, z_decoded)
      self$add_loss(loss, inputs = inputs)
      x
    }
  )
)

layer_variational <- function(object) { 
  create_layer(CustomVariationalLayer, object, list())
}

y <- list(input_img, z_decoded) %>% 
  layer_variational() 

vae <- keras_model(input_img, y)

vae %>% compile(
  optimizer = "rmsprop",
  loss = NULL, 
  experimental_run_tf_function=FALSE
)

```


```{r, echo=TRUE, results='hide', eval=FALSE}

vae %>% fit(
  x = x_train, y = NULL,
  epochs = 10,
  batch_size = batch_size,
  validation_data = list(x_test, NULL)
)

vae %>% save_model_weights_tf("noKL_vae2/noKL_vae")

```


```{r}

load_model_weights_tf(vae, "noKL_vae/noKL_vae")

```


```{r, eval = solution}

generate_num()

```

## Exercise 4

Draw a sketch of the VAE that we elaborated so that you understand the different layers that were used.


